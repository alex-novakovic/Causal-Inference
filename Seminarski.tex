\documentclass[12pt, a4paper]{article}

\usepackage{authblk}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[serbianc]{babel}
\usepackage{hyperref}
\usepackage{amsmath}

\renewcommand\Authsep{\par}
\renewcommand\Authands{\par}

\title{Увод у каузално (узрочно) закључивање}
\author{Александра Новаковић 368/22}
\author{Милица Ињац 338/18}
\author{Бојан Корда 121/19}
\affil{Математички факултет, Универзитет у Београду}
\date{\today}

\begin{document}
\maketitle
\newpage

\tableofcontents
\newpage

\section{Фундаментални проблем}
\newpage



\section{Рандомизирани експеримент}
\newpage



\section{Опсервационе студије}

\subsection{Увод}
За разлику од рандомизираног експеримента, где се третман насумично додељује међу изабраним јединицама или се насумично бира скуп јединица за сваку врсту третмана, опсервационе студије су студије у којима истраживач посматра шта се дешава у реалном свету, без контролисања или мењања услова. У односу на рандомизирани експеримент, опсервационе студије имају неколико предности и мана. Њихова предност огледа се у широм спектру популације који можемо посматрати, уштеди средстава која су потребна за рандомизирани експеримент, као и већој екстерној валидности с обзиром да опсервационе студије показују како третмани или понашања заиста утичу на људе у свакодневном животу. Међутим, мана ове врсте студија је сама чињеница да додела третмана није одабрана као у претходном случају, већ постоје многобројни додатни утицаји како на исход, тако и на саму доделу третмана. Њих називамо конфаудерима тј. сметајућим коваријатама.  Дакле, опсервационе студије представљају истраживања у којима механизам доделе третмана није под контролом истраживача, али га можемо проценити регуларним, што ће омогућити да донесемо закључке о каузалног ефекту налик процени у оквиру рандомизираног експеримента. То постижемо различитим алатима којима ћемо контролисати коваријате. Циљ контролисања коваријата је да унутар субпопулација дефинисаних истим вредностима коваријата, додела третмана буде независна од потенцијалних исхода, како би се, пре свега елиминисали ефекти конфаундера који би могли утицати на сам ефекта третмана.
Један релевантан пример би била студија где желимо да проценимо ефекат редовног вежбања на здравље срца. Међутим, уколико у обзир не узмемо старост посматраног појединца, нећемо добити јасну процену. Због тога, старост и остале конфаудере морамо да контролишемо, тј. урачунамо њихов утицај. 
//Опсервационе студије се могу поделити у две кључне фазе, фазу дизајна и анализе. У оквиру фазе дизајна, прелиминарном анализом података о коваријатама и додели третмана, а без употребе података о исходу, конструишемо узорак или план анализе који обезбеђује што бољи баланс коваријата између третиране и контролне групе. Овај приступ је паралелан фази дизајна у стратификованим рандомизованим експериментима, где је баланс гарантован самим дизајном. То се, у случају опсервационих студија, постиже на различите начине и помоћу разних алата. 

\subsubsection{Кључни алати и коцепти у фази дизајна}
Фаза дизајна фокусура се искључиво на податке о додели третмана и претретманским коваријатама, док се подаци о исходу се не користе. Дизајнирање опсервационе студије без увида у податке о исходу је кључно јер спречава истраживача да свесно или несвесно прилагоди модел како би одговарао унапред замишљеним резултатима. 
Ова фаза обухвата неколико повезаних корака којима се имплементира концепт балансирајућих мера, од којих је најважнија Propensity Score. Балансирајућа мера је функција коваријата која има својство да, када се на њу услови, вероватноћа добијања активног третмана постаје независна од самих коваријата. Propensity Score, u ознаци e(x), предтавља посебну врста балансирајуће мере, дефинисана као условна вероватноћа пријема третмана условљена коваријатама.  
Кључни део фазе дизајна је процена степена баланса у дистрибуцијама коваријата између третиране и контролне групе. Идеално би било када би коваријате имале сличне вредности у обе групе, али с обзиром да то веома често није случај, када проценимо разлике међу њима користимо разне методе како би се тај баланс побољшао. За почетак  процењујемо Propensity score који заправо представља вероватноћу да одређена јединица прими третман, да бисмо његовом применом могли да наставимо са дизајном. Веома важну улогу у овој фази има  Matching (упаривање) које спроводимо тако да за сваку третирану јединицу проналазимо одговарајућу контролну у смислу Propensity Score-а или Махаланобисове метрике. Следи Trimming (одбацивање), поступак где се одбацују јединице за које Propensity Score вредности указују на недостатак преклапања. Недостатак преклапања указује на то да јединице са супротним третманом имају веома различите вредности коваријата, што чини екстраполацију нетачном и осетљивом. Иако се фаза дизајна првенствено бави балансом, она такође укључује прелиминарне анализе за процену плуазибилности кључне, али нетестибилне, претпоставке незабњуивости (Unconfoundness).

\subsubsection{Кључни алати и концепти у фази анализе}
Када смо завршили са фазом дизајна, податке који су у оквиру те фазе припремљени и балансирани коришћењем Propensity score-a узимамо и примењујемо различите технике за коначну, валидну процену каузалног ефекта. За почетак, радимо субкласификацију/постстратификацију на Propensity score-у. То постижемо тако што делимо узорак на подкласе на основу дистрибуције  Propensity Score-a. У идеалном случају, коваријате су избалансиране и студију  третирамо као да је спроведен стратификовани рандомизовани експеримент. Даље, просечни ефекат третмана се процењује као пондерисани просек разлика у просечним исходима између третиране и контролне групе унутар сваког стратума тј. подкласе. Због тога је веома значајна тежинска регресија. Пондери су углавном засновани на величини подкласе. Такође, субкласификација се често комбинује са другим методама ради додатног прилагођавања за евентуалне преостале разлике у коваријатама унутар слојева. Регресија је један од алата, који се може користити за прилагођавање за преостали небеланс коваријата, чиме процене чини прецизнијим. Модел базирана анализа користи регресиони модел како би импутирала недостајуће потенцијалне исходе за третиране јединице и на тај начин решавамо преостале мале разлике у коваријатама унутар парова.

\subsection{Дизајн фаза}
У овом делу разлажемо критичне претпоставке и коцепте који морају бити успостављени пре анализе исхода. 

\subsubsection{Игнорабилност и регуларни механизми доделе}
Раније смо већ поменули регуларне механизме доделе и напоменули да уколико можемо проценити нашу доделу третмана регуларном, онда можемо проценити и каузални ефекат. Јако је важно да можемо да претпоставимо да се ради о оваквој додели, јер у супртоном каузална интерпретација постаје веома нестабилна. Када се ради о рандомизираном експерименту, сам његов дизајн обезбеђује поменуту претпоставку. Када је реч о опсервационим студијама, разматрамо три кључна сегмента која заједничким именом називамо игнорабилност и под чијим условом можемо сматрати да имамо регуларни механизам доделе. 
Формално, игнорабилност је независност потенцијалних исхода од доделе третмана условљеном коваријатама: $$(Y(0), Y(1)) \perp T \mid X$$. Регуларни механизам доделе је начин доделе третмана који је предвидив и зависи само од познатих карактеристика, што омогућава валидно поређење група у опсервационој студији.

Да би игнорабилност била испуњена треба да важе три услова.
1.SUTVА ( индивидуалистичка додела)
Третман примењен на једну јединицу не утиче на исход за друге јединице.
Јединица која прима специфични ниво третмана не може примити различите облике тог третмана.
2.Услов позитивности (пробабилистичка додела)
Механизам доделе $\Pr(W \mid X, Y(0), Y(1))$ је пробабилистички ако је вероватноћа доделе третмана за јединицу i строго између нуле и један тј. свака јединица има могућност да буде додељена и активном третману и контролном третману
3. Незбуњивост (Неконфундираност)
Механизам доделе је незбуњив уколико не зависи од потенцијалних исхода: $\text{Pr}(W \mid X, Y(0), Y(1)) =`\text{Pr}(W \mid X, Y'(0), Y'(1))$ за све $W, X, Y(0), Y(1), Y'(0)$ и $Y'(1)$
Ова претпоставка је нетестибилна и врло вероватно на самом почетку није испуњена, али коришћењем различитих метода можемо је учинити плаузибилном. То постижемо прилагођавањем (контролом) свих посматраних коваријата. Ако је механизам незбуњив, можемо избацити потенцијалне исходе као аргументе и писати механизам додељивања као  $Pr(W \mid X)$. 

\subsubsection{Propensity scores}
Горе поменути услов позитивности захтева да Propensity Score $e(x) = \text{Pr}(D_i = 1 \mid X_i = x) = E[W_i \mid X_i = x]$ који је формално дефинисан као условна вероватноћа пријема третмана $$(D_i=1)$$, буде строго већи од нуле и строго мањи од јединице.  У опсервационим студијама, прави propensity score готово никада није познат, већ се мора проценити, обично коришћењем логистичке регресије. Спецификација модела за Propensity Score може укључивати само линеарну везу коваријата, а можемо по потреби додати и квадратне и интеракционе термине. Кључна разлика у процени Propensity Score-а за каузално закључивање је у томе што циљ није добити најтачнију оцену хипотетички истинског Propensity Score-а, већ пронаћи спецификацију која постиже адекватан баланс коваријата у узорку. Често се дешава да коришћење процењеног Propensity Score-а доводи до бољег баланса у узорку него коришћење правог, супер-популационог Propensity Score-а.
Баланс се проверава након што се узорак стратификује (подели) на подкласе (блокове) према процењеном Propensity Score-у, тако што се проверава да ли су просеци коваријата слични између третиране и контролне групе унутар тих подкласа. О томе ћемо више говорити у фази анализе.
Применом регресије $\text{logit}(\Pr(D_i = 1 \mid X_i)) = \beta_0 + \beta_1 X_{i1} + \dots + \beta_k X_{ik}$ добијамо процену ове вероватноће \[
e(X_i) = \Pr(D_i = 1 \mid X_i)
\]
На овај начин, све коваријате смо сложили у једну скаларну врендост што је од изузетног значаја за даљу анализу.

\subsubsection{Matching}
Упаривање се заснива на налажењу директних поређења за сваку јединицу.  Примарни циљ упаривања је да креирамо под-узорак јединица у којем су дистрибуције коваријата између третиране и контролне групе боље избалансиране. За дату третирану јединицу са одређеним скупом вредности коваријата тражимо контролну јединицу са што сличнијим скупом коваријата. На пример, претпоставимо да желимо да проценимо ефекат програма обуке за посао на исходе на тржишту рада за одређену особу, рецимо, тридесетогодишњу жену са троје деце млађе од 10 година, са завршеним факултетом и три године радног искуства, која је прошла кроз програм обуке. У овом случају коваријатама сматрамо број деце, њихову старост, ниво образовањаи године искуства. У приступу упаривања циљ је да пронађемо особу из контролне групе која има исте вредности коваријата. Међутим, уколико не можемо пронаћи такву јединицу овај приступ постаје теже изводљив. Можемо тражити старију жену али са више радног искуства или млађу жену са мање деце и мање радног искуства.
Да бисмо успешно применили упаривање, неопходна је метрика удаљености, која нам омогућава да проценимо колико су две јединице сличне. Постоји неколико начина да израчунамо тражену метрику, а најчешће су следеће:
1. Метрика за упаривање на основу линеаризованог propensity score-a:
Линеаризовани  propensity score је $$\ell(x) = \ln\left(\frac{1 - e(x)}{e(x)}\right)$$ па је метрика рачуната у односу на њега дата формулом $$d_\ell(x, x') = (\ell(x) - \ell(x'))^2$$, где су x i x' вектори коваријата за јединице којима процењујемо сличност.
2. Махаланобисова метрика:
$$d_{\text{mahal}}(x, x') = (x - x')' V_{\text{mahal}}^{-1} (x - x')$$, где је {\text{mahal}} коваријатна матрица коваријата x, која узима у обзир варијансу и корелацију између свих коваријата. Када се користи Махаланобисова метрика за упаривање, матрица тежине $V_{\text{mahal}}$ се обично заснива на просеку матрица коваријансе унутар третиране ($D_i=1$) и контролне ($D_i=0$) групе:
\[
V_{\text{mahal}} = \frac{1}{2} \left( \hat{\Sigma}_c + \hat{\Sigma}_t \right)
\]
Где су  $\hat{\Sigma}_c$ (или $S_c$) узорочна матрица коваријансе коваријата у контролној групи  $\hat{\Sigma}_t$ (или $S_t$) узорочна матрица коваријансе коваријата у третираној групи.

Затим, када имамо метрику, постоји више принципа упаривања, а кључна стратегија је у погледу тога да ли конролне јединице могу бити коришћене више пута. Тако, имамо могућност:
1.Упаривања без замене
-Свака контролна јединица се може користити само једном као пар третираној јединици
-Користи се секвенцијални алгоритам упаривања (sequential/greedy matching algorithm). Јединице се обично сортирају (нпр. на основу Propensity Score-а), а затим се секвенцијално упарују, почевши од јединица које је најтеже упарити (most difficult to match). Јединице се често сортирају према опадајућој вредности propensity score-a и упарују се тим редоследом.
2.Упаривање са заменом
-Контролна јединица може бити употребљена као најбољи пар више пута за различите третиране јединице
-Ова метода олакшава рачунање и побољшава квалитет упаривања јер једна контролна јединица може послужити као најбољи пар за више сличних третираних јединица. Такође, резултат не зависи од редоследа упаривања
-Уводи компликације у процену варијансе због зависности између парова

Иако смо до сада често говорили о просечном ефекту третмана (АТЕ), упаривање је, због своје природе, првенствено усмерено на процену другог естиманда, тј. просечног ефекта третмана за третиране јединице (ATT). Упаривање обично настоји да пронађе што сличније контролне јединице за сваку третирану. Ово резултира скупом података који је релевантан за процену каузалног ефекта само за подпопулацију третираних јединица. Процедуре упаривања могу се проширити како би се проценио и укупни АТЕ (просечан ефекат третмана за цео узорак) тако што би се упаривање применило и на контролне јединице, али је то у већини случајева непрактично, тако да користимо друге методе како бисмо на крају заиста добили просечни ефекат третмана за цео узорак.

Упаривање је ретко савршено, јер увек постоји извесна неусклађеност у коваријатама, $X_i - X_{m(i)}$, између третиране јединице и њеног пара. Због тога једноставна разлика у исходима након упаривања (неприлагођени естиматор $\hat{\tau}^{\text{unadj}}$) може задржати преосталу јединичну пристрасност. Ова пристрасност настаје јер потенцијални исход контролне јединице$ Y_i(0)$није савршен сурогат за недостајући потенцијални исход третиране јединице  $Y_i(1)$ , управо услед преостале разлике у коваријатама. Постоје поступци прилагођавања пристрасности  којима се овај ефекат може ублажити, најчешће применом линеарне регресије на дискрепанцу у упаривању и корекцијом неприлагођене процене ефекта. Ипак, с обзиром на то да ће се у наставку анализе спровести додатни кораци као што су trimming, субкласификација и пондерисање, који у значајној мери редукују преостали bias, прилагођавање пристрасности у овом раду нећемо спроводити ради једноставности и практичности поступка.

\subsubsection{Trimming}
Повезано са упаривањем је и коришћење технике Trimming-а, тј., одбацивања лоших парова. Уколико је најближи пар за третирану јединицу и даље значајно различит (дистанца прелази одређену границу), та третирана јединица се може избацити из анализе. Одбацивање јединица за које не постоји одговарајућа у супротној третманској групи осигурава да закључци буду изведени само за подпопулацију где постоји довољно преклапања, чиме се повећава интерна валидност и кредибилитет. 
За јединице са вредностима коваријата таквим да је Propensity Score (PS) близу нуле или један, тешко је добити прецизне процене типичног ефекта третмана. Уколико је вероватноћа да јединица прими третман близу јединици, биће више третираних у односу на контролне јединице, и обрнуто, уколико је поменута вероватноћа блиска нули. Тада, поређења захтевају екстраполацију, чинећи закључке непоузданим. Из тог разлога, одбацујемо јединице са екстремним вредностима propensity score-a, и на тај начин мењамо естиманд, тј. меримо ефекат за подпопулацију, са propensity score-ом унутар одређеног опсега. Интервал за prpensity score који се поставља је облика $(\alpha, 1-\alpha)$ и на тај начин добијамо поузданији резултат. Дакле, скуп јединица који посматрамо може се записати на следећи начин:  C^* = \{ x \in X \mid \alpha \le e(x) \le 1 - \alpha \} \quad. 
Међутим, потребно је на прави начин одредити \alpha.  Алгоритам прво проверава да ли је  задржавање целог узорка, C=X, могуће и статистички пожељно. То се проверава неједнакошћу која укључује просечну вредност инверзне варијансе propensity score-a $$\frac{1}{N} \sum_{i=1}^{N} \hat{e}(X_i) \cdot (1 - \hat{e}(X_i)) \le 2$$.
Ако ова неједнакост не важи, то значи да екстремне вредности пропенсити скора превише утичу на варијансу, па је потребно одбацивање јединица. У том случају, \gamma се дефинише као највећа вредност која задовољава услов
 $$
\frac{1}{N} \sum_{i=1}^{N} \hat{e}(X_i) \cdot (1 - \hat{e}(X_i)) \cdot 
\mathbf{1}\{ \hat{e}(X_i)(1 - \hat{e}(X_i)) \ge \frac{1}{\gamma} \}
= 
\gamma \cdot \frac{1}{N} \sum_{i=1}^{N} 
\mathbf{1}\{ \hat{e}(X_i)(1 - \hat{e}(X_i)) \ge \frac{1}{\gamma} \}
$$
Тада је оптимална граница $\alpha$ дата на следећи начин:
$$\alpha = \frac{1}{2} - \sqrt{\frac{1}{4} + \frac{1}{\gamma}}$$
Коначно, избацују се све јединице, чији је propensity score изван интервала  $(\alpha, 1-\alpha)$.


\subsection{Фаза анализе}
\subsubsection{Субкласификација}
Субкласификација је водећи приступ у анализи података са регуларним механизмом доделе третмана и користи се за естимацију каузалних ефеката након што је већ извршено потенцијално тримовање у фази дизајна. 
Будући да у опсервационим студијама обично постоји превише коваријата које узимају превише различитих вредности, то чини директну стратификацију на основу свих коваријата неизводљивом. Због тога, узорак се дели на подкласе тј. блокове применом процењеног propensity score-a \hat{e}(X_i), који је скаларна функција коваријата. Иако propensity score није директна коваријата, он је довољан да се, условно на његову вредност, елиминише пристрасност повезана са разликама у свим осталим коваријатама.
Узорак  делимо на подкласе (блокове), тако да је унутар сваке подкласе процењени propensity score приближно константан. Након поделе, податке се анализирамо као да су настали из стратификованог рандомизованог експеримента, где се додела третмана сматра потпуно насумичном унутар сваке подкласе. Та подела се спроводи заправо на основу вредности већ поменутог линеаризованог propensity score-a.
$$\ell(X_i) = \ln \left( \frac{1 - \hat{e}(X_i)}{\hat{e}(X_i)} \right)$$
Дефинишемо интервал који је подскуп интервала који смо користили за триминг па самим тим представља подскуп јединица које имају довољан преклоп (overlap).
Границе интервала b_0 \quad \text{и} \quad b_J постављају се на основу најмањих и највећих процењених вероватноћа доделе третмана у обе групе.  За доњу границу узимамо најмању вредност те вероватноће међу третираним јединицама:
$$\hat{e}_c = b_0 = \min_{i: D_i = 1} \hat{e}(X_i)$$
, док за горњу границу узимамо његову највећу вредност међу контролним јединицама:
$$\hat{e}_t = b_J = \max_{i: D_i = 0} \hat{e}(X_i)$$.
Овај потез осигурава да у преосталом узорку не постоје јединице за које нема поређења у супротној групи. Алгоритам за субкласификацију затим креће са једним блоком (J=1) дефинисаним претходним интервалом. Унутрашње границе bj проналазе се кроз процес у коме се постојећи, неадекватно балансирани блокови деле на мање, све док унутрашња варијација пропенсити скора не постане прихватљиво мала.
\\Први корак је процена адекватности где се за сваки тренутни блок ј израчунава статистика која тестира нулту хипотезу да је просечна вредност линеаризованог propensity score-a иста за тестиране и контролне јединице унутар тог блока.
\\Блок j који је неадекватно балансиран цепа се само ако су испуњена два минимална услова.  
Услов минималне величине јединице (): Цепање блока мора резултирати у два нова подстратума, од којих сваки мора имати минимални број јединица сваког третманског типа (третирани и контролни)N_{\min,1} \ge 3 \quad \text{за сваки тип}
Услов минималне укупне величине (): Укупан број јединица у новом подстратуму мора бити довољно велик ( нпр. N_{\min,2} \ge K + 2, где је К број коваријата за које се планира додатно прилагођавање. Ако су ови услови испуњени, блок је погодан за цепање.
Уколико се блок цепа, нова гранична вредност bi(која постаје горња граница старог, доњег блока, а доња граница старог горњег блока) поставља се на медијану вредности propensity score-a свих јединица које се тренутно налазе у том блоку.
Процес се понавља — итерацијама се проверавају сви новонастали блокови и цепају се они који су неадекватно балансирани и довољно велики. Алгоритам се зауставља када су сви добијени блокови или адекватно балансирани (према t-статистици) или премали за даље цепање. Овај процес даје коначни скуп граничних вредности bj које дефинишу J подкласа за анализу.

\subsubsection{Модел базирани приступ}

Такође, у оквиру сваког блока пожељно је додатно побољшати прецизност коришћењем линеарне регресије, с обзиром да је propensity score у блоковима приближан међу јединицама, а не потпуно једнак. 
Модел-базирано прилагођавање унутар ових блокова служи за додатно смањење преостале пристрасности и обезбеђује највећу могућу прецизност.  У пракси, након субкласификације, модел-базирано прилагођавање се спроводи тако што се унутар сваког блока j процењује регресиони модел $Y^{\text{obs}} = \alpha(j) + \tau(j) \cdot D_i + X_i \beta(j) + \epsilon_i$,  где је $Y_i^{\text{obs}}$ је посматрани исход, $D_i$ индикатор третмана, $X_i\beta(j)$ представља линеарно прилагођавање коваријатама унутар блока, а параметри $\alpha(j), \tau(j), \beta(j)$ се оцењују искључиво на основу јединица унутар блока.
Овај приступ омогућава да се унутар блока коригују преостале разлике у коваријатама, слично регресијском прилагођавању у рандомизованим експериментима, и резултује субкласификационим оцењивачем са додатним прилагођавањем $\hat{\tau}^{\text{strat, adj}}$.


\subsubsection{Пондерисање}
Пондерисање, тачније увођење тежинске регресије је једна од кључних метода анализе која се користи за превазилажење пристрасности у опсервационим студијама, где не постоји гаранција да су групе за третман и контролу упоредиве као у рандомизованим експериментима.
Пондери, тј тежине у регресији уско су повезане са propensity score-om, који користимо за њихово израчунавање тако да ефективно ребалансирају дистрибуцију коваријата између третиране и контролне групе. Циљ је да се креира виртуелни узорак у којем је додела третмана неконфундирана, омогучавајући непристрасну оцену ефекта третмана (Average Treatment Effect, ATE).
Први корак је рачунање пондера. Ховиц томпсонове тежине Тежина A_i^{ht}, за сваку јединицу i рачуна се као инверзна вероватноћа њеног стварног примања третмана или контроле, условљена њеним коваријатама.
Дакле формула за контролну јединицу би изгледала овако: A_i^{ht}=\frac{1}{\hat{e}(X_i)}. Ове тежине се често нормализују како би се побољшала прецизност.
На овај начин, јединици која је имала малу вероватноћу да буде третирана дајемо већу тежину, о обзиром да је она била сличнија контролној групи по карактеристикама, па тако на неки начин добијемо најбољу слику о томе шта би се десило да је јединица из контролне групе добила третман. Слишно важи за јединице из конреолне групе које су имале велик вероватноћу да приме третман.
Када смо израчунали пондер, даље, за рачунање просечног ефекта третмана, неизоставан је Ховиц-Томпсонов оцењивач, којим се рачуна просечан исход третираних и контролних јединица. 
E\left[ \frac{e(X_i)}{W_i} Y_i^{obs} \right] = E_{sp}[Y_i(1)], за третирану јединицу
E\left[ \frac{1 - e(X_i)}{1 - W_i} Y_i^{obs} \right] = E_{sp}[Y_i(0)], за контролну јединицу.
Да бисте ове теоријске очекиване вредности претворили у вредности које се могу израчунати (оцењиваче) из Вашег коначног узорка (N), Ви очекивања замењујете емпиријским просецима (сумама):
\hat{Y}(1) = \frac{1}{N_1} \sum_{i=1}^{N} \frac{W_i \, Y_i^{obs}}{\hat{e}(X_i)} за јединице из третиране групе, и \hat{Y}(0) = \frac{1}{N} \sum_{i=1}^{N} \frac{(1 - W_i) \, Y_i^{obs}}{1 - \hat{e}(X_i)} за јединице из контролне групе.

\hat{\tau}^{ht} = \hat{Y}(1) - \hat{Y}(0)=\hat{Y}(1) = \frac{1}{N_1} \sum_{i=1}^{N} \frac{W_i \, Y_i^{obs}}{\hat{e}(X_i)} - \hat{Y}(0) = \frac{1}{N} \sum_{i=1}^{N} \frac{(1 - W_i) \, Y_i^{obs}}{1 - \hat{e}(X_i)}. 
На крају, процена каузалног ефекта је \tau_{sp} = E_{sp}[Y_i(1) - Y_i(0)] =\tau_{sp} = E_{sp}[Y_i(1)] - E_{sp}[Y_i(0)]
Ховиц-Томпсонов оцењивач 
Најчешћи начин на који се овај оцењивач имплементира у статистичком софтверу, попут R-а, јесте кроз пондерисану регресију најмањих квадрата (Weighted Least Squares – WLS)
Додавање коваријата: Метода пондерисања је толико флексибилна да се у оквиру ове исте WLS регресије могу додати и коваријате (Xi). Укључивање коваријата у пондерисану регресију чини оцењивач "двоструко робусним" (double-robustness)
Све поменуто се једном када израчунамо пондер спроводи путем тежинске регресије задате на следећи начин Y_i^{obs} = \alpha + \tau \cdot W_i + \epsilon_i.

Уколико смо вршили субкласификацију а затим модел базирани приступ, онда се пондерисање врши на следећи начин.
Оцењивање укупног ефекта (Агрегација)
Након што се добије оцењени ефекат третмана \tau^{\text{adj}}(j) из регресије за сваки блок, укупни просечни ефекат третмана за цео узорак \big(\tau^{\text{strat, adj}}\big) добија се пондерисањем унутар-блок оцењивача са релативном величином блока.
Једначина агрегације (коју извори називају субкласификациони оцењивач) је:
$$\hat{\tau}^{\text{strat}} = \sum_{j=1}^{J} q(j) \cdot \hat{\tau}^{\text{dif}}(j) \text{$$
Где је q(j) = \frac{N(j)}{N} је релативна величина блока (стратума) j у односу на цео узорак N. Пондери се користе како би се оценио просечан ефекат третмана за цео узорак.




